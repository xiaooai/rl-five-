"""
åŸºæœ¬åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""
import numpy as np
import torch
from game.environment import GomokuEnvironment
from model.network import ActorCritic
from ppo.agent import PPOAgent


def test_environment():
    """æµ‹è¯•æ¸¸æˆç¯å¢ƒ"""
    print("æµ‹è¯•æ¸¸æˆç¯å¢ƒ...")
    env = GomokuEnvironment(15)
    
    # æµ‹è¯•é‡ç½®
    state = env.reset()
    assert state.shape == (3, 15, 15), f"çŠ¶æ€å½¢çŠ¶é”™è¯¯: {state.shape}"
    print("âœ“ ç¯å¢ƒé‡ç½®æ­£å¸¸")
    
    # æµ‹è¯•æœ‰æ•ˆåŠ¨ä½œ
    valid_actions = env.get_valid_actions()
    assert len(valid_actions) == 225, f"æœ‰æ•ˆåŠ¨ä½œæ•°é‡é”™è¯¯: {len(valid_actions)}"
    print("âœ“ æœ‰æ•ˆåŠ¨ä½œè·å–æ­£å¸¸")
    
    # æµ‹è¯•æ‰§è¡ŒåŠ¨ä½œ
    action = 112  # ä¸­å¿ƒä½ç½®
    state, reward, done, info = env.step(action)
    assert not done, "ç¬¬ä¸€æ­¥ä¸åº”è¯¥ç»“æŸæ¸¸æˆ"
    print("âœ“ åŠ¨ä½œæ‰§è¡Œæ­£å¸¸")
    
    print("æ¸¸æˆç¯å¢ƒæµ‹è¯•é€šè¿‡ï¼\n")


def test_network():
    """æµ‹è¯•ç¥ç»ç½‘ç»œ"""
    print("æµ‹è¯•ç¥ç»ç½‘ç»œ...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    network = ActorCritic(15, 512).to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 4
    state = torch.randn(batch_size, 3, 15, 15).to(device)
    action_probs, action_log_probs, value = network(state)
    
    assert action_probs.shape == (batch_size, 225), f"åŠ¨ä½œæ¦‚ç‡å½¢çŠ¶é”™è¯¯: {action_probs.shape}"
    assert action_log_probs.shape == (batch_size, 225), f"åŠ¨ä½œå¯¹æ•°æ¦‚ç‡å½¢çŠ¶é”™è¯¯: {action_log_probs.shape}"
    assert value.shape == (batch_size, 1), f"ä»·å€¼å½¢çŠ¶é”™è¯¯: {value.shape}"
    print("âœ“ ç½‘ç»œå‰å‘ä¼ æ’­æ­£å¸¸")
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    action_mask = torch.ones(batch_size, 225).to(device)
    action, log_prob, value = network.get_action(state, action_mask)
    
    assert action.shape == (batch_size, 1), f"åŠ¨ä½œå½¢çŠ¶é”™è¯¯: {action.shape}"
    assert log_prob.shape == (batch_size, 1), f"å¯¹æ•°æ¦‚ç‡å½¢çŠ¶é”™è¯¯: {log_prob.shape}"
    assert value.shape == (batch_size, 1), f"ä»·å€¼å½¢çŠ¶é”™è¯¯: {value.shape}"
    print("âœ“ åŠ¨ä½œé€‰æ‹©æ­£å¸¸")
    
    print("ç¥ç»ç½‘ç»œæµ‹è¯•é€šè¿‡ï¼\n")


def test_agent():
    """æµ‹è¯•PPOæ™ºèƒ½ä½“"""
    print("æµ‹è¯•PPOæ™ºèƒ½ä½“...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    agent = PPOAgent(15, 512, device=device)
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    env = GomokuEnvironment(15)
    state = env.reset()
    action_mask = env.get_action_mask()
    
    action, log_prob, value = agent.get_action(state, action_mask)
    assert isinstance(action, int), f"åŠ¨ä½œç±»å‹é”™è¯¯: {type(action)}"
    assert isinstance(log_prob, float), f"å¯¹æ•°æ¦‚ç‡ç±»å‹é”™è¯¯: {type(log_prob)}"
    assert isinstance(value, float), f"ä»·å€¼ç±»å‹é”™è¯¯: {type(value)}"
    print("âœ“ æ™ºèƒ½ä½“åŠ¨ä½œé€‰æ‹©æ­£å¸¸")
    
    # æµ‹è¯•ç»éªŒæ”¶é›†
    rollout_stats = agent.collect_rollout(env, 100)
    assert 'episode_rewards' in rollout_stats, "ç»éªŒæ”¶é›†ç¼ºå°‘episode_rewards"
    assert 'episode_lengths' in rollout_stats, "ç»éªŒæ”¶é›†ç¼ºå°‘episode_lengths"
    print("âœ“ ç»éªŒæ”¶é›†æ­£å¸¸")
    
    # æµ‹è¯•ç­–ç•¥æ›´æ–°
    if len(agent.rollout_buffer) > 0:
        update_stats = agent.update(1, 32)
        assert 'policy_loss' in update_stats, "ç­–ç•¥æ›´æ–°ç¼ºå°‘policy_loss"
        print("âœ“ ç­–ç•¥æ›´æ–°æ­£å¸¸")
    
    print("PPOæ™ºèƒ½ä½“æµ‹è¯•é€šè¿‡ï¼\n")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹åŸºæœ¬åŠŸèƒ½æµ‹è¯•...\n")
    
    try:
        test_environment()
        test_network()
        test_agent()
        
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¡¹ç›®åŸºæœ¬åŠŸèƒ½æ­£å¸¸ã€‚")
        print("\nå¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼š")
        print("python train.py")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
